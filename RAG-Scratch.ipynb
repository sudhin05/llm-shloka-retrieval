{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a low level conceptual exploration of RAG. Using a word vector encoder to embed words, calculating the mean vector of documents and prompts, and using manhattan distance as a distance metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.85337  ,  0.011645 , -0.033377 , -0.31981  ,  0.26126  ,\n",
       "        0.16059  ,  0.010724 , -0.15542  ,  0.75044  ,  0.10688  ,\n",
       "        1.9249   , -0.45915  , -3.3887   , -1.2152   , -0.054263 ,\n",
       "       -0.20555  ,  0.54706  ,  0.4371   ,  0.25194  ,  0.0086557,\n",
       "       -0.56612  , -1.1762   ,  0.010479 , -0.55316  , -0.15816  ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Gensim is an open-source library for unsupervised topic modeling, document indexing, retrieval by similarity, and other natural language processing functionalities, using modern statistical machine learning.\n",
    "Gensim is implemented in Python and Cython for performance.\n",
    "\"\"\"\n",
    "import gensim.downloader\n",
    "\n",
    "word_encoder = gensim.downloader.load('glove-twitter-25')\n",
    "word_encoder['apple']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-6.3483393e-01,  1.3683620e-01,  2.0645106e-01, -2.1831200e-01,\n",
       "       -1.8181981e-01,  2.6023200e-01,  1.3276964e+00,  1.7272198e-01,\n",
       "       -2.7881199e-01, -4.2115799e-01, -4.7215199e-01, -5.3013992e-02,\n",
       "       -4.6326599e+00,  4.3883198e-01,  3.6487383e-01, -3.6672002e-01,\n",
       "       -2.6924044e-03, -3.0394283e-01, -5.5415201e-01, -9.1787003e-02,\n",
       "       -4.4997922e-01, -1.4819117e-01,  1.0654800e-01,  3.7024397e-01,\n",
       "       -4.6688594e-02], dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def embed_sequence(sequence):\n",
    "    vects = word_encoder[sequence.split(' ')]\n",
    "    return np.mean(vects, axis=0)\n",
    "\n",
    "embed_sequence('its a sunny day today')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "def calc_distance(embedding1, embedding2):\n",
    "    return cdist(np.expand_dims(embedding1, axis=0), np.expand_dims(embedding2, axis=0), metric='cityblock')[0][0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "similar phrases:\n",
      "8.496297497302294\n",
      "different phrases:\n",
      "11.832107525318861\n"
     ]
    }
   ],
   "source": [
    "print('similar phrases:')\n",
    "print(calc_distance(embed_sequence('sunny day today')\n",
    "                  , embed_sequence('rainy morning presently')))\n",
    "\n",
    "print('different phrases:')\n",
    "print(calc_distance(embed_sequence('sunny day today')\n",
    "                  , embed_sequence('perhaps reality is painful')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = {\"menu\": \"ratatouille is a stew thats twelve dollars and fifty cents also gazpacho is a salad thats thirteen dollars and ninety eight cents also hummus is a dip thats eight dollars and seventy five cents also meat sauce is a pasta dish thats twelve dollars also penne marinera is a pasta dish thats eleven dollars also shrimp and linguini is a pasta dish thats fifteen dollars\",\n",
    "             \"events\": \"on thursday we have karaoke and on tuesdays we have trivia\",\n",
    "             \"allergins\": \"the only item on the menu common allergen is hummus which contain pine nuts\",\n",
    "             \"info\": \"the resteraunt was founded by two brothers in two thousand and three\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retreive_relevent(prompt, documents=documents):\n",
    "    min_dist = 1000000000\n",
    "    r_docname = \"\"\n",
    "    r_doc = \"\"\n",
    "\n",
    "    for docname, doc in documents.items():\n",
    "        dist = calc_distance(embed_sequence(prompt)\n",
    "                           , embed_sequence(doc))\n",
    "\n",
    "        if dist < min_dist:\n",
    "            min_dist = dist\n",
    "            r_docname = docname\n",
    "            r_doc = doc\n",
    "\n",
    "    return r_docname, r_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finding relevent doc for \"what pasta dishes do you have\"\n",
      "('menu', 'ratatouille is a stew thats twelve dollars and fifty cents also gazpacho is a salad thats thirteen dollars and ninety eight cents also hummus is a dip thats eight dollars and seventy five cents also meat sauce is a pasta dish thats twelve dollars also penne marinera is a pasta dish thats eleven dollars also shrimp and linguini is a pasta dish thats fifteen dollars')\n",
      "----\n",
      "finding relevent doc for \"what events do you guys do\"\n",
      "('events', 'on thursday we have karaoke and on tuesdays we have trivia')\n"
     ]
    }
   ],
   "source": [
    "prompt = 'what pasta dishes do you have'\n",
    "print(f'finding relevent doc for \"{prompt}\"')\n",
    "print(retreive_relevent(prompt))\n",
    "print('----')\n",
    "prompt = 'what events do you guys do'\n",
    "print(f'finding relevent doc for \"{prompt}\"')\n",
    "print(retreive_relevent(prompt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retreive_and_agument(prompt, documents=documents):\n",
    "    docname, doc = retreive_relevent(prompt, documents)\n",
    "    return f\"Answer the customers prompt based on the folowing documents:\\n==== document: {docname} ====\\n{doc}\\n====\\n\\nprompt: {prompt}\\nresponse:\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (1.58.1)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from openai) (4.7.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from openai) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from openai) (0.8.2)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from openai) (2.10.4)\n",
      "Requirement already satisfied: sniffio in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from openai) (4.66.4)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from openai) (4.12.2)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from anyio<5,>=3.5.0->openai) (3.7)\n",
      "Requirement already satisfied: certifi in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (2024.2.2)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (2.27.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\hp\\appdata\\roaming\\python\\python312\\site-packages (from tqdm>4->openai) (0.4.6)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'OPENAI_API_TOKEN' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[28], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39msystem(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpip install openai\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mopenai\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m openai\u001b[38;5;241m.\u001b[39mapi_key \u001b[38;5;241m=\u001b[39m \u001b[43mOPENAI_API_TOKEN\u001b[49m\n\u001b[0;32m      6\u001b[0m prompts \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwhat pasta dishes do you have\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwhat events do you guys do\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124moh cool what is karaoke\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m prompt \u001b[38;5;129;01min\u001b[39;00m prompts:\n",
      "\u001b[1;31mNameError\u001b[0m: name 'OPENAI_API_TOKEN' is not defined"
     ]
    }
   ],
   "source": [
    "!pip install openai\n",
    "import openai\n",
    "\n",
    "openai.api_key = OPENAI_API_TOKEN\n",
    "\n",
    "prompts = ['what pasta dishes do you have', 'what events do you guys do', 'oh cool what is karaoke']\n",
    "\n",
    "for prompt in prompts:\n",
    "\n",
    "    ra_prompt = retreive_and_agument(prompt)\n",
    "    response = openai.Completion.create(model=\"gpt-3.5-turbo-instruct\", prompt=ra_prompt, max_tokens=80).choices[0].text\n",
    "\n",
    "    print(f'prompt: \"{prompt}\"')\n",
    "    print(f'response: {response}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
